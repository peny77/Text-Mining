{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code By <a href=\"https://www.facebook.com/peny.ismail.77\">Peny Ismail</a> - <a href=\"https://github.com/peny77\">Github</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> dataset tocsv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer() \n",
    "stop = stopwords.words('english')\n",
    "stop.append(\"new\")\n",
    "stop.append(\"like\")\n",
    "stop.append(\"u\")\n",
    "stop.append(\"it'\")\n",
    "stop.append(\"'s\")\n",
    "stop.append(\"n't\")\n",
    "stop.append('mr.')\n",
    "stop = set(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "\n",
    "    tokens_ = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
    "\n",
    "    tokens = []\n",
    "    for token_by_sent in tokens_:\n",
    "        tokens += token_by_sent\n",
    "\n",
    "    tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "    tokens = list(filter(lambda t: t not in [u\"'s\", u\"n't\", u\"...\", u\"''\", u'``', u'\\u2014', u'\\u2026', u'\\u2013'], tokens))\n",
    "     \n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        token = wnl.lemmatize(token)\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    filtered_tokens = list(map(lambda token: token.lower(), filtered_tokens))\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = True         #Tambah Baris\n",
    "        self.convert_charrefs= True #Tambah Baris\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(tokens, num):\n",
    "    return Counter(tokens).most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "def build_article_df(urls):\n",
    "    articles = []\n",
    "    for index, row in urls.iterrows():\n",
    "        try:\n",
    "            data=row['text'].strip().replace(\"'\", \"\")\n",
    "            data = strip_tags(data)\n",
    "            soup = BeautifulSoup(data)\n",
    "            data = soup.get_text()\n",
    "            data = data.encode('ascii', 'ignore').decode('ascii')\n",
    "            document = tokenizer(data)\n",
    "            top_5 = get_keywords(document, 5)\n",
    "          \n",
    "            unzipped = zip(*top_5)\n",
    "            kw= list(unzipped[0])\n",
    "            kw=\",\".join(str(x) for x in kw)\n",
    "            articles.append((kw, row['title'], row['pubdate']))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #print data\n",
    "            #break\n",
    "            pass\n",
    "        #break\n",
    "    article_df = pd.DataFrame(articles, columns=['keywords', 'title', 'pubdate'])\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "def tokenizer(text):\n",
    "\n",
    "    tokens_ = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
    "\n",
    "    tokens = []\n",
    "    for token_by_sent in tokens_:\n",
    "        tokens += token_by_sent\n",
    "\n",
    "    tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "    tokens = list(filter(lambda t: t not in [u\"'s\", u\"n't\", u\"...\", u\"''\", u'``', u'\\u2014', u'\\u2026', u'\\u2013'], tokens))\n",
    "     \n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        token = wnl.lemmatize(token)\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    filtered_tokens = list(map(lambda token: token.lower(), filtered_tokens))\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = True         #Tambah Baris\n",
    "        self.convert_charrefs= True #Tambah Baris\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def get_keywords(tokens, num):\n",
    "    return Counter(tokens).most_common(num)\n",
    "\n",
    "\n",
    "def build_article_df(urls):\n",
    "    articles = []\n",
    "    for index, row in urls.iterrows():\n",
    "        try:\n",
    "            data=row['text'].strip().replace(\"'\", \"\")\n",
    "            data = strip_tags(data)\n",
    "            soup = BeautifulSoup(data)\n",
    "            data = soup.get_text()\n",
    "            data = data.encode('ascii', 'ignore').decode('ascii')\n",
    "            document = tokenizer(data)\n",
    "            top_5 = get_keywords(document, 3)\n",
    "          \n",
    "            unzipped = list(zip(*top_5)) #tambah list\n",
    "            kw= list(unzipped[0])\n",
    "            kw=\",\".join(str(x) for x in kw)\n",
    "            articles.append((kw, row['title'], row['pubdate']))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #print data\n",
    "            #break\n",
    "            pass\n",
    "        #break\n",
    "    article_df = pd.DataFrame(articles, columns=['keywords', 'title', 'pubdate'])\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Permalink</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8938</td>\n",
       "      <td>Building a Data Culture</td>\n",
       "      <td>&lt;a href=\"http://ericbrown.com/wp-content/uploa...</td>\n",
       "      <td>20141118</td>\n",
       "      <td>http://ericbrown.com/building-data-culture.htm</td>\n",
       "      <td>Big Data|People</td>\n",
       "      <td>Big Data|culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8943</td>\n",
       "      <td>Note to Self - Don't say \"Data Driven\" Anymore</td>\n",
       "      <td>&lt;a href=\"http://ericbrown.com/wp-content/uploa...</td>\n",
       "      <td>20141120</td>\n",
       "      <td>http://ericbrown.com/dont-say-data-driven-anym...</td>\n",
       "      <td>Big Data|Leadership</td>\n",
       "      <td>Big Data|data-driven|Knowledge Management|Orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8948</td>\n",
       "      <td>Foto Friday - Titmouse on the Feeder</td>\n",
       "      <td>I captured this Titmouse on the backporch feed...</td>\n",
       "      <td>20141121</td>\n",
       "      <td>http://ericbrown.com/foto-friday-titmouse-feed...</td>\n",
       "      <td>Foto Friday</td>\n",
       "      <td>Photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8952</td>\n",
       "      <td>The Cloud - Gateway to Enterprise Mobility</td>\n",
       "      <td>&lt;em&gt;This post is brought to you by the&lt;/em&gt; &lt;a...</td>\n",
       "      <td>20141121</td>\n",
       "      <td>http://ericbrown.com/cloud-gateway-enterprise-...</td>\n",
       "      <td>Information Technology|Strategy|Technology|The...</td>\n",
       "      <td>cloud|mobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8957</td>\n",
       "      <td>The Agile Data Center</td>\n",
       "      <td>&lt;a href=\"http://ericbrown.com/wp-content/uploa...</td>\n",
       "      <td>20141124</td>\n",
       "      <td>http://ericbrown.com/agile-data-center.htm</td>\n",
       "      <td>Data Center|Information Technology|The New CIO</td>\n",
       "      <td>Agility|Data center|flexibility</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           Title  \\\n",
       "0  8938                         Building a Data Culture   \n",
       "1  8943  Note to Self - Don't say \"Data Driven\" Anymore   \n",
       "2  8948            Foto Friday - Titmouse on the Feeder   \n",
       "3  8952      The Cloud - Gateway to Enterprise Mobility   \n",
       "4  8957                           The Agile Data Center   \n",
       "\n",
       "                                             Content      Date  \\\n",
       "0  <a href=\"http://ericbrown.com/wp-content/uploa...  20141118   \n",
       "1  <a href=\"http://ericbrown.com/wp-content/uploa...  20141120   \n",
       "2  I captured this Titmouse on the backporch feed...  20141121   \n",
       "3  <em>This post is brought to you by the</em> <a...  20141121   \n",
       "4  <a href=\"http://ericbrown.com/wp-content/uploa...  20141124   \n",
       "\n",
       "                                           Permalink  \\\n",
       "0     http://ericbrown.com/building-data-culture.htm   \n",
       "1  http://ericbrown.com/dont-say-data-driven-anym...   \n",
       "2  http://ericbrown.com/foto-friday-titmouse-feed...   \n",
       "3  http://ericbrown.com/cloud-gateway-enterprise-...   \n",
       "4         http://ericbrown.com/agile-data-center.htm   \n",
       "\n",
       "                                          Categories  \\\n",
       "0                                    Big Data|People   \n",
       "1                                Big Data|Leadership   \n",
       "2                                        Foto Friday   \n",
       "3  Information Technology|Strategy|Technology|The...   \n",
       "4     Data Center|Information Technology|The New CIO   \n",
       "\n",
       "                                                Tags  \n",
       "0                                   Big Data|culture  \n",
       "1  Big Data|data-driven|Knowledge Management|Orga...  \n",
       "2                                        Photography  \n",
       "3                                     cloud|mobility  \n",
       "4                    Agility|Data center|flexibility  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "df = pd.read_csv('tes/tocsv.csv')\n",
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    data.append((row['Title'], row['Permalink'], row['Date'], row['Content']))\n",
    "data_df = pd.DataFrame(data, columns=['title' ,'url', 'pubdate', 'text' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Driving Digital by Isaac Sacolick - a book review</td>\n",
       "      <td>http://ericbrown.com/driving-digital-isaac-sac...</td>\n",
       "      <td>20170906</td>\n",
       "      <td>&lt;img class=\"alignleft size-medium wp-image-975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Data and Culture go hand in hand</td>\n",
       "      <td>http://ericbrown.com/?p=9757</td>\n",
       "      <td>-11130</td>\n",
       "      <td>Last week, I spent an afternoon talking to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Data Quality - The most important data dimension?</td>\n",
       "      <td>http://ericbrown.com/data-quality-most-importa...</td>\n",
       "      <td>20170918</td>\n",
       "      <td>&lt;img class=\"size-medium wp-image-9764 alignrig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Be pragmatic, not dogmatic</td>\n",
       "      <td>http://ericbrown.com/be-pragmatic-not-dogmatic...</td>\n",
       "      <td>20170928</td>\n",
       "      <td>&lt;img class=\"alignright size-medium wp-image-97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>The Data Way</td>\n",
       "      <td>http://ericbrown.com/the-data-way.htm</td>\n",
       "      <td>20171003</td>\n",
       "      <td>&lt;img class=\"alignleft size-medium wp-image-977...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "143  Driving Digital by Isaac Sacolick - a book review   \n",
       "144                   Data and Culture go hand in hand   \n",
       "145  Data Quality - The most important data dimension?   \n",
       "146                         Be pragmatic, not dogmatic   \n",
       "147                                       The Data Way   \n",
       "\n",
       "                                                   url   pubdate  \\\n",
       "143  http://ericbrown.com/driving-digital-isaac-sac...  20170906   \n",
       "144                       http://ericbrown.com/?p=9757    -11130   \n",
       "145  http://ericbrown.com/data-quality-most-importa...  20170918   \n",
       "146  http://ericbrown.com/be-pragmatic-not-dogmatic...  20170928   \n",
       "147              http://ericbrown.com/the-data-way.htm  20171003   \n",
       "\n",
       "                                                  text  \n",
       "143  <img class=\"alignleft size-medium wp-image-975...  \n",
       "144  Last week, I spent an afternoon talking to the...  \n",
       "145  <img class=\"size-medium wp-image-9764 alignrig...  \n",
       "146  <img class=\"alignright size-medium wp-image-97...  \n",
       "147  <img class=\"alignleft size-medium wp-image-977...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = build_article_df(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data,big,culture</td>\n",
       "      <td>Building a Data Culture</td>\n",
       "      <td>20141118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data,data-driven,make</td>\n",
       "      <td>Note to Self - Don't say \"Data Driven\" Anymore</td>\n",
       "      <td>20141120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>captured,canon,titmouse</td>\n",
       "      <td>Foto Friday - Titmouse on the Feeder</td>\n",
       "      <td>20141121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobility,organization,device</td>\n",
       "      <td>The Cloud - Gateway to Enterprise Mobility</td>\n",
       "      <td>20141121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data,center,agile</td>\n",
       "      <td>The Agile Data Center</td>\n",
       "      <td>20141124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fog,shot,get</td>\n",
       "      <td>When life gives you a little fog...</td>\n",
       "      <td>20141203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>captured,canon,sunrise</td>\n",
       "      <td>Foto Friday - Sunrise on Isle of Palms</td>\n",
       "      <td>20141205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>slideshare,dissertation,view</td>\n",
       "      <td>Dissertation Defense Slides on Slideshare</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>risk,cmo,cio</td>\n",
       "      <td>Are you avoiding risk or managing risk?</td>\n",
       "      <td>20141208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cio,organization,sidelined</td>\n",
       "      <td>The Sidelined CIO</td>\n",
       "      <td>20141209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       keywords  \\\n",
       "0              data,big,culture   \n",
       "1         data,data-driven,make   \n",
       "2       captured,canon,titmouse   \n",
       "3  mobility,organization,device   \n",
       "4             data,center,agile   \n",
       "5                  fog,shot,get   \n",
       "6        captured,canon,sunrise   \n",
       "7  slideshare,dissertation,view   \n",
       "8                  risk,cmo,cio   \n",
       "9    cio,organization,sidelined   \n",
       "\n",
       "                                            title   pubdate  \n",
       "0                         Building a Data Culture  20141118  \n",
       "1  Note to Self - Don't say \"Data Driven\" Anymore  20141120  \n",
       "2            Foto Friday - Titmouse on the Feeder  20141121  \n",
       "3      The Cloud - Gateway to Enterprise Mobility  20141121  \n",
       "4                           The Agile Data Center  20141124  \n",
       "5             When life gives you a little fog...  20141203  \n",
       "6          Foto Friday - Sunrise on Isle of Palms  20141205  \n",
       "7       Dissertation Defense Slides on Slideshare  20141206  \n",
       "8         Are you avoiding risk or managing risk?  20141208  \n",
       "9                               The Sidelined CIO  20141209  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_array=[]\n",
    "for index, row in article_df.iterrows():\n",
    "    keywords=row['keywords'].split(',')\n",
    "    for kw in keywords:\n",
    "        keywords_array.append((kw.strip(' '), row['keywords']))\n",
    "\n",
    "kw_df = pd.DataFrame(keywords_array).rename(columns={0:'keyword', 1:'keywords'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>data,big,culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>big</td>\n",
       "      <td>data,big,culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>culture</td>\n",
       "      <td>data,big,culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data</td>\n",
       "      <td>data,data-driven,make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-driven</td>\n",
       "      <td>data,data-driven,make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>make</td>\n",
       "      <td>data,data-driven,make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>captured</td>\n",
       "      <td>captured,canon,titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>canon</td>\n",
       "      <td>captured,canon,titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>titmouse</td>\n",
       "      <td>captured,canon,titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobility</td>\n",
       "      <td>mobility,organization,device</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword                      keywords\n",
       "0         data              data,big,culture\n",
       "1          big              data,big,culture\n",
       "2      culture              data,big,culture\n",
       "3         data         data,data-driven,make\n",
       "4  data-driven         data,data-driven,make\n",
       "5         make         data,data-driven,make\n",
       "6     captured       captured,canon,titmouse\n",
       "7        canon       captured,canon,titmouse\n",
       "8     titmouse       captured,canon,titmouse\n",
       "9     mobility  mobility,organization,device"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = kw_df.keywords.tolist()\n",
    "names = kw_df.keyword.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_array = []\n",
    "for item in document:\n",
    "    items = item.split(',')\n",
    "    document_array.append((items))\n",
    "\n",
    "occurrences = OrderedDict((name, OrderedDict((name, 0) for name in names)) for name in names)\n",
    "\n",
    "# Find the co-occurrences:\n",
    "for l in document_array:\n",
    "    for i in range(len(l)):\n",
    "        for item in l[:i] + l[i + 1:]:\n",
    "            occurrences[l[i]][item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occur = pd.DataFrame.from_dict(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occur.to_csv('tes/ericbrown_co-occurancy_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>big</th>\n",
       "      <th>culture</th>\n",
       "      <th>data-driven</th>\n",
       "      <th>make</th>\n",
       "      <th>captured</th>\n",
       "      <th>canon</th>\n",
       "      <th>titmouse</th>\n",
       "      <th>mobility</th>\n",
       "      <th>organization</th>\n",
       "      <th>...</th>\n",
       "      <th>shutter</th>\n",
       "      <th>science</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>management</th>\n",
       "      <th>love</th>\n",
       "      <th>song</th>\n",
       "      <th>quality</th>\n",
       "      <th>pragmatic</th>\n",
       "      <th>dogmatic</th>\n",
       "      <th>thats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agile</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agility</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytics</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avalanche</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           data  big  culture  data-driven  make  captured  canon  titmouse  \\\n",
       "7d            0    0        0            0     0         3      3         0   \n",
       "abstract      0    0        0            0     0         0      0         0   \n",
       "agile         9    0        0            0     0         0      0         0   \n",
       "agility       0    0        0            0     0         0      0         0   \n",
       "always        3    0        0            0     0         0      0         0   \n",
       "analytics     9    0        0            0     0         0      0         0   \n",
       "another       0    0        0            0     0         0      9         0   \n",
       "area          0    0        0            0     0         0      0         0   \n",
       "ask           0    0        0            0     0         0      0         0   \n",
       "avalanche     0    0        0            0     0         0      0         0   \n",
       "\n",
       "           mobility  organization  ...  shutter  science  knowledge  \\\n",
       "7d                0             0  ...        0        0          0   \n",
       "abstract          0             0  ...        0        0          0   \n",
       "agile             0             0  ...        0        0          0   \n",
       "agility           0             0  ...        0        0          0   \n",
       "always            0             0  ...        0        0          0   \n",
       "analytics         0             0  ...        0        0          0   \n",
       "another           0             0  ...        0        0          0   \n",
       "area              0             0  ...        0        0          0   \n",
       "ask               0             0  ...        0        0          0   \n",
       "avalanche         0             0  ...        0        0          0   \n",
       "\n",
       "           management  love  song  quality  pragmatic  dogmatic  thats  \n",
       "7d                  0     0     0        0          0         0      0  \n",
       "abstract            0     0     0        0          0         0      0  \n",
       "agile               0     0     0        0          0         0      0  \n",
       "agility             0     0     0        0          0         0      0  \n",
       "always              0     0     0        0          0         0      0  \n",
       "analytics           0     0     0        0          0         0      0  \n",
       "another             0     0     0        0          0         0      0  \n",
       "area                0     0     0        0          0         0      0  \n",
       "ask                 0     0     0        0          0         0      0  \n",
       "avalanche           0     0     0        0          0         0      0  \n",
       "\n",
       "[10 rows x 211 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occur.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Teks Mining.png'/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
